{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ImjwR5LNPFmp",
    "nbpresent": {
     "id": "91c274e0-fca3-4d42-85dc-c37c53758873"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# RNN next character prediction\n",
    "\n",
    "### Mehrdad Yazdani\n",
    "### November 12, 2018\n",
    "\n",
    "Colab notebook online to play!!\n",
    "\n",
    "https://colab.research.google.com/drive/1achzCaBFBHputcqXrw_o_He5UNjx3hFG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "0b8370a1-cced-4d4e-ba18-31f6336a9f2d"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Aim: learn the basics of Recurrent Neural Networks in PyTorch!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "### 1) Conceptual-math background for Deep Learning\n",
    "\n",
    "### 2) The Elman Recurrent Neural Network \n",
    "\n",
    "### 3) Example: predicting the next character from observing previous characters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Caveat\n",
    "\n",
    "We will only consider one input sequence and one output sequence:\n",
    "\n",
    "- **Input sequence:** hihell\n",
    "- **Output sequence:** ihello\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Important to clarify that this example demonstrates memorization and not learning! \n",
    "\n",
    "The network has simply memorized to regurgitate what it has seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We need to follow good machine learning practice of having training and hold-out test sets.\n",
    "\n",
    "Our main aim is covering RNNs in PyTorch and we assume you already know this ðŸ˜‡\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conceptual-math background for Deep Learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### In machine learning, we represent objects as *vectors*\n",
    "\n",
    "Just a collection of $n$ numbers (fixed-sized array):\n",
    "<center>\n",
    "    <b>x</b> $=  (x_1, x_2, \\ldots, x_n) $\n",
    "</center>\n",
    "\n",
    "- A data matrix consists of rows of vectors\n",
    "- An image is a vector\n",
    "- A sequence is an ordered collection of vectors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Each object is represented as a vector\n",
    "\n",
    "### We would like to measure the similarity between objects\n",
    "\n",
    "### The dot/inner product is a measure of similarity between vectors \n",
    "<br>\n",
    "<br>\n",
    "<center> $x^{T}y = \\sum_{i}^{n} x_{i}y_{i}$ </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Each object is a vector and the inner product is a measure of similarity between vectors \n",
    "\n",
    "$x^{T}y = \\begin{bmatrix} x_{1} & x_{2} & \\ldots &  x_{n}\\end{bmatrix} \\begin{bmatrix} y_{1}\\\\  y_{2}\\\\ \\vdots \\\\  y_{n} \\end{bmatrix} = x_{1}y_{1} + x_{2}y_{2} + \\ldots + x_{n}y_{n} = \\sum_{i}^{n} x_{i}y_{i} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The inner product is a measure of *mismatch* between two vectors\n",
    "\n",
    "- If $x^{T}y$ is large and positive, then $x$ and $y$ are *aligned* together. Otherwise they are mismatched! \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The matrix vector product: mismatch between a collection of vectors against a vector \n",
    "\n",
    "- $Wx$ measures the mismatch between $x$ and the $m$ row vectors $w_{i}^{T}$ (note the slight abuse in notation)\n",
    "\n",
    "$ y = Wx = \\begin{bmatrix} w^{T}_{1}\\\\  w^{T}_{2}\\\\ \\vdots \\\\  w^{T}_{m} \\end{bmatrix} \\begin{bmatrix} x_{1}\\\\  x_{2}\\\\ \\vdots \\\\  x_{n} \\end{bmatrix} = \\begin{bmatrix} w^{T}_{1}x\\\\  w^{T}_{2}x\\\\ \\vdots \\\\  w^{T}_{m}x \\end{bmatrix} =  w_{1}^{T}x +  w_{2}^{T}x + \\ldots +  w_{m}^{T}x = \\sum_{i}^{m} w_{i}^{T}x $\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "$ y = Wx = \\begin{bmatrix} w^{T}_{1}\\\\  w^{T}_{2}\\\\ \\vdots \\\\  w^{T}_{m} \\end{bmatrix} \\begin{bmatrix} x_{1}\\\\  x_{2}\\\\ \\vdots \\\\  x_{n} \\end{bmatrix} = \\begin{bmatrix} w^{T}_{1}x\\\\  w^{T}_{2}x\\\\ \\vdots \\\\  w^{T}_{m}x \\end{bmatrix} =  w_{1}^{T}x +  w_{2}^{T}x + \\ldots +  w_{m}^{T}x = \\sum_{i}^{m} w_{i}^{T}x $\n",
    "</center>\n",
    "\n",
    "Example: collection of 3D vectors $w_{1}, w_{2}, w_{3}$ against the 3D vector $x$:\n",
    "<center>\n",
    "<img src=\"https://www.walletfox.com/course/qtconcurrentmatrixvectorSource/matvec1_img.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Fourier Transform as a form of template matching \n",
    "\n",
    "![fft](./figures/fft.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Fourier Transform as a form of template matching\n",
    "\n",
    "\n",
    "- Each row in the DFT matrix is a basis function (sinusoid) \n",
    "\n",
    "\n",
    "- Basis functions can be used together to create other functions and sometimes called a *kernel*; we can think of them as templates "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The idea behind the Fourier transform is to take a signal and measure how much the signal matches the collection of templates \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We can think of the Fourier transform as taking the raw signal to be represented as as a *template representation*\n",
    "\n",
    "- This new representation is more useful for downstream tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Deep learning in one slide? \n",
    "\n",
    "- The templates in Fourier transforms are fixed to be sinusoids. In Deep learning, we *learn* the templates from data:\n",
    "\n",
    "<center>\n",
    "$z_0 = \\sigma(W_{0}x+b_{0})$\n",
    "<center>\n",
    "    $\\downarrow$    \n",
    "<center>\n",
    "    $z_1 = \\sigma(W_{1}z_{0}+b_{1})$\n",
    "<center>\n",
    "    $\\downarrow$\n",
    "<center>\n",
    "    $\\vdots$\n",
    "<center>\n",
    "    $\\downarrow$\n",
    "<center>    \n",
    "$z_L = \\sigma(W_{L}z_{L-1}+b_{L-1})$\n",
    "<center>\n",
    "    $\\downarrow$\n",
    "<center>\n",
    "$y = W_{L+1}z_{L}+b_{L}$\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $\\sigma(\\cdot)$ are non-linear activation functions\n",
    "- Intermediate representations $z_{i}$ are called *hidden states*\n",
    "- $W_{i}$ and $b_{i}$ are templates and bias terms to get representations $z_{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Elman RNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The deep learning framework we presented gives us a tool to take a given input $x$ and transform it to a desired output $y$ through intermediate hidden hierarchical representations $z_{i}$\n",
    "<center>\n",
    "$ y = V\\sigma(U x)$\n",
    "</center>\n",
    "\n",
    "- This framework works great for a single input $x$ and a single output $y$\n",
    "\n",
    "- But what if we have *sequences* of inputs and targets? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We need a way to have a notion of \"memory\" since past inputs also have an influence on the output\n",
    "\n",
    "<center>\n",
    "$ y_{t} \\stackrel{?}{=} f(x_{t}, x_{t-1})$\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Recurrent Neural Networks generalize the static input and output pairs $(x, y)$ for sequences of inputs and outputs $(x_{t}, y_{t})$, for $t$ in $\\{0, 1, \\ldots\\}$.\n",
    "\n",
    "<center>\n",
    "    <br>\n",
    "$h_{t} = \\sigma(U x_{t} + V h_{(t-1)})$\n",
    "<center>    \n",
    "$y_{t} =W h_{t} $\n",
    "   \n",
    "![elman](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Recurrent_neural_network_unfold.svg/1000px-Recurrent_neural_network_unfold.svg.png)\n",
    " \n",
    "- Without feedback, we are not capturing the past history. If we set $V = 0$ we get back to the previous framework: $h_{t} = \\sigma(U x_{t})$ and $y_{t} =W h_{t} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example: predicting the next character from observing previous characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Next character prediction \n",
    "\n",
    "We will only consider one input sequence and one output sequence:\n",
    "\n",
    "- **Input sequence:** hihell\n",
    "- **Output sequence:** ihello\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We need to follow good machine learning practice of having training and hold-out test sets.\n",
    "\n",
    "Our main aim is covering RNNs in PyTorch and we assume you already know this ðŸ˜‡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4c80cd29-19cf-4768-958e-6ad1a3f39a3e"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One way of thinking about how this works is that the machine learning algorithm (ML) first sees the character \"h\" and tries to guess what should follow:\n",
    "\n",
    "\"h\" â†’ ML â†’ \"?\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the ideal case and if it has learned, the ML will output \"i\". \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If we do this for all the characters, in this exercise we would like to see the ML algorithm at the end to have this property:\n",
    "\n",
    "\"h\" â†’ ML â†’\"i\"<br>\n",
    "\"i\"  â†’ ML â†’ \"h\"<br>\n",
    "\"h\" â†’ ML â†’ \"e\"<br>\n",
    "\"e\" â†’ ML â†’ \"l\"<br>\n",
    "\"l\"  â†’ ML â†’ \"l\"<br>\n",
    "\"l\"  â†’ ML â†’ \"o\"<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2f5f8f49-5b67-4556-8be7-87c74d2981ed"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "- This notebook is mostly lifted and modified from the excellent tutorials by Sung Kim:\n",
    "https://docs.google.com/presentation/d/17VUX7YXhMkJrqO5gNGh6EE5gzBpY-BF9IrfVKcFIb3A/edit#slide=id.g27c9a844e4_157_9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uon6zrqWtpYH",
    "nbpresent": {
     "id": "1ba09160-dde2-469c-8de9-f6fae31a0277"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Encoding characters with numbers\n",
    "\n",
    "\n",
    "\n",
    "A popular way to deal with encoding characters instead is to treat all characters as equally important and assign a one-hot encoding scheme. It is easiest to illustrate this:\n",
    "\n",
    "\"h\" â†’ 1000 <br>\n",
    "\"e\" â†’ 0100 <br>\n",
    "\"l\" â†’ 0010 <br>\n",
    "\"o\" â†’ 0001 <br>\n",
    "\n",
    "We have a sequence of 4D vectors! This is perfect for RNNs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.031163Z",
     "start_time": "2018-11-12T07:48:59.025234Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "yFd2WVJqPFms",
    "nbpresent": {
     "id": "147cd3d4-5983-4707-bcf9-0b751168fcad"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# One hot encoding for each char in 'hello'\n",
    "h = [1, 0, 0, 0]\n",
    "e = [0, 1, 0, 0]\n",
    "l = [0, 0, 1, 0]\n",
    "o = [0, 0, 0, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r689k5GvPFmw",
    "nbpresent": {
     "id": "1279ae9f-d0ab-404c-a8fb-9e42ee52135f"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Elman RNN in PyTorch: `nn.RNN`\n",
    "\n",
    "![elman](figures/nn.RNN.png)\n",
    "\n",
    "`nn.RNN` in PyTorch implements the following RNN: \n",
    "\n",
    "$ h_{t} = \\text{tanh}(w_{ih}x_{t} + b_{ih} + w_{hh}h_{(t-1)} + b_{hh})$\n",
    "\n",
    "- $w_{ih}$ and $b_{ih}$ are the weights and biases for the input $x_{t}$\n",
    "- $w_{hh}$ and $b_{hh}$ are the weights and biases for the previous hidden state $h_{(t-1)}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.296273Z",
     "start_time": "2018-11-12T07:48:59.037010Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "WaQwdaqHPFml",
    "nbpresent": {
     "id": "b4092e7f-28a8-499c-94c8-912a106960d1"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c679c4e3-b578-46d6-a92b-ecb9d87ed071"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "nn.RNN\n",
    "Important parameters that need to be specified:\n",
    "\n",
    "- `input_size`: The number of expected features in the input `x`\n",
    "- `hidden_size`: The number of features in the hidden state `h`\n",
    "\n",
    "Since our 1-one-hot vectors are only 4 dimensional, we need the `input_size` of the RNN to be 4. The `hidden_size` is the dimension of the hidden state. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Once `nn.RNN` has been defined, it takes two inputs (`x` and initial state `h_0`) and returns two outputs (`output` set of states and final state`h_n`). The inputs are:\n",
    "\n",
    "- input of shape (seq_len, batch, input_size): tensor containing the features of the input sequence.\n",
    "- `h_0` of shape (num_layers * num_directions, batch, hidden_size): tensor containing the initial hidden state for each element in the batch. \n",
    "\n",
    "The outputs are:\n",
    "\n",
    "- `output` of shape (seq_len, batch, num_directions * hidden_size): tensor containing the output features (h_k) from the last layer of the RNN, for each k. \n",
    "- `h_n` (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for `n = seq_len.` \n",
    "\n",
    "For each element in the input sequence, each layer computes the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.303872Z",
     "start_time": "2018-11-12T07:48:59.298856Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "1iwwB8hyPFmx",
    "nbpresent": {
     "id": "2c495ce3-5f8c-496b-922b-f613a189e177"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# The RNN cell will take two sets of inputs:\n",
    "#  - inputs x with 4 features; we specify the number of features with input_size\n",
    "#  - hidden state h with 2 features; we specify the number of hidden features \n",
    "#    with hidden_size = 2\n",
    "     \n",
    "elman_rnn = nn.RNN(input_size=4, hidden_size=2, batch_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K_5eIgFpPFm1",
    "nbpresent": {
     "id": "d9a7920b-f640-4fae-a28d-10687c74e4a1"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The above line has instantiated a elman_rnn object for us to process *sequences* of data that takes state and input data. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O8rMdTlBuJLk",
    "nbpresent": {
     "id": "6cde1006-89e3-4c8e-94d2-82a508f122cd"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Prep the initial hidden state tensor\n",
    "When we start the RNN, we need to select something for the initial hidden state $h_0$. Here lets pick something from a random normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.319502Z",
     "start_time": "2018-11-12T07:48:59.306730Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OkXHj8K5PFm1",
    "nbpresent": {
     "id": "3dcbe8d5-48dd-4187-a36b-4cd88dd608f7"
    },
    "outputId": "dce41093-8928-4430-a712-31a9636c825c",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# To make a 2 dimensional hidden state vector, we make the initial hidden state\n",
    "# h_0 with the tensor size specified as:\n",
    "#\n",
    "#     (num_layers * num_directions, batch_size, hidden_size) \n",
    "#\n",
    "# (swap if batch_first = True when RNN cell was created above)\n",
    "\n",
    "hidden = Variable(torch.randn(1, 1, 2))\n",
    "hidden.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MqsdmtdRX4cc",
    "nbpresent": {
     "id": "391ef101-a890-489f-825e-b9acb618352d"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The hidden state will have two features! \n",
    "\n",
    "- Since we only have 1 hidden layer, and only batch size of 1 (we only have one sequence), we expect the hidden state vector to be a 1 x 1 x 2 tensor. \n",
    "\n",
    "- `hidden.size()` above verifies that we have initialized the tensor with the correct shape. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8W19i-akuu0H",
    "nbpresent": {
     "id": "83479630-8391-4fda-a800-b8b0d47b176a"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Prep the initial input sequence character\n",
    "\n",
    "Now let's propogate an input character through the RNN cell. We will first convert our list of one-hot encoded characters to a PyTorch tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.329324Z",
     "start_time": "2018-11-12T07:48:59.322783Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ukd6NxofPFm6",
    "nbpresent": {
     "id": "745c1b54-3104-4dfc-b14a-eb1efd3983fd"
    },
    "outputId": "0786a18c-f176-402c-c722-7ede1da4b77d",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Propagate input through RNN\n",
    "# Input: (batch, seq_len, input_size) when batch_first=True\n",
    "input_characters = Variable(torch.Tensor([h, e, l, l, o]))\n",
    "\n",
    "input_characters.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Since our one-hot encoded vectors are 4 dimensional, and our \"hello\" sequence consists of 5 characters, we except the input tensor to have size 5 x 4. We see that using `input_characters.size()` that this is indeed the case. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JVYgDH3mPFm_",
    "nbpresent": {
     "id": "654878b6-3a8a-4935-bc60-328c87e4ca39"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "\n",
    "Note that our `inputs` tensor is missing the batch dimension. In this case, since we only have 1 sequence (so just one batch), the `inputs` tensor needs to have a size `[1, 5, 4]` - we can easily reshape the tensor using the `.view(1,5,4)` method. Or, we could just do `.view(1,5,-1)` where the -1 will take care of the left over dimensions for us.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QBwS8bcfvANE",
    "nbpresent": {
     "id": "4af492f4-620d-4813-bb0c-be5b7af9ee23"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inference with RNN (aka \"forward pass\"): one character at a time\n",
    "\n",
    "OK, lets **finally** take our initial hidden state and the first character encoded characters and pass it to the Elman RNN that we defined as `elman_rnn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.338812Z",
     "start_time": "2018-11-12T07:48:59.331518Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "0qB7-8-RNyeD",
    "nbpresent": {
     "id": "2b09c257-fd3b-4d90-ac3b-784f48971ea0"
    },
    "outputId": "3646fd07-92b2-4859-9a6b-c634ba5d8bfa",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "out, hidden = elman_rnn(input_characters[0,:].view(1,1,-1), hidden)\n",
    "print(\"Encoded character size:\", input_characters[0,:].size(), \n",
    "      \"\\nhidden size:\", hidden.size() ,\n",
    "      \"\\nout size:\", out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wRutv7VaQK4j",
    "nbpresent": {
     "id": "d174d7dd-9813-445d-9620-3f3a10db12e5"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `elman_rnn` expects two sets of input tensors: \n",
    "    - the input character (note singular)\n",
    "    - the hidden state (note singular)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We have stored all characters in the 5x4 tensor `input_characters`\n",
    "- We pass the first character using \"slice\" indexing: `input_characters[0,:]`\n",
    "    - When we slice this way, you will only get a 1D tensor that has 4 elements.\n",
    "    - But RNN expects a *sequential tensor* w/ shape (seq_len, batch, input_size) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- So we have to reshape this 1D tensor into 3D by introducing some dummy dimensions. This reshaping can be done with the `.view()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "Below we will iteratre through each 1-hot-encoded character and see the output and hidden sizes of the RNN outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.355472Z",
     "start_time": "2018-11-12T07:48:59.341061Z"
    },
    "code_folding": [],
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "lYNFSdOtPFnB",
    "nbpresent": {
     "id": "6e4c6250-84c2-4609-9be5-203c095e6edd"
    },
    "outputId": "e2b1edb4-dd75-45b0-f95e-2cee7aaa626e",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "for i, one_hot_encoded_encoded in enumerate(input_characters):\n",
    "    encoded_character = one_hot_encoded_encoded.view(1, 1, -1)\n",
    "    # Input: (batch, seq_len, input_size) when batch_first=True\n",
    "    out, hidden = elman_rnn(encoded_character, hidden)\n",
    "    print(\"Character\", i, \"tensor sizes:\")\n",
    "    print(\"  encoded char size:\", encoded_character.size(), \n",
    "          \"; hidden size:\", hidden.size() ,\n",
    "          \";  out size:\", out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VRdi9QltZl_W",
    "nbpresent": {
     "id": "2076a0c1-1829-4419-8fc0-9a7a9d8f19f4"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We see that for every character, the input tensor has been reshaped as a 4 dimensional 1-hot-encoded vector with tensor size 1x1x4. \n",
    "\n",
    "\n",
    "- The RNN cell then takes produces *two* tensors: `out` and `hidden`. `hidden` is just the output of the RNN state for the next time step $h_{t+1}$. The out and hidden tensors have the same shape. \n",
    "\n",
    "\n",
    "- This is because `out` is just a copy of the `hidden`. \n",
    "\n",
    "### Exercise: Verify `out` is a copy of the `hidden` state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.371427Z",
     "start_time": "2018-11-12T07:48:59.358119Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "X06k_L33ZQxH",
    "nbpresent": {
     "id": "9a03d9b8-1b5f-43e1-8060-ed0e143b6f4a"
    },
    "outputId": "96d35018-144e-41d0-b3a3-4541f70ea118",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ohXkVMnPFnF",
    "nbpresent": {
     "id": "b49b85dd-d159-430e-a5e7-f4bf0c1e86c1"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Indeed! We see that the `hidden` and `out` tensors that the RNN cell returns are not only equal in shape but also in value. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YFYxNT1KwcuW",
    "nbpresent": {
     "id": "04499caa-7afa-42ac-9eca-413b165da159"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inference with RNN: going through entire sequence in one shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.383252Z",
     "start_time": "2018-11-12T07:48:59.375596Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "xEEIrWMnPFnF",
    "nbpresent": {
     "id": "e1dc180a-9bb2-47c1-89a2-8f75b4d71cba"
    },
    "outputId": "af1b5ebd-d5e2-43b4-e0d6-62d817c32fa0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "input_characters = input_characters.view(1, 5, -1)\n",
    "out, hidden = elman_rnn(input_characters, hidden)\n",
    "print(\"sequence of encoded character size\",input_characters.size(), \"\\nhidden size\", hidden.size(), \"\\nout size\", out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h_oUoJKaPFnJ",
    "nbpresent": {
     "id": "1c455491-079c-4777-abf0-6d32d6b751ff"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "`out` is the hidden states for **every time step**. `hidden` is the hidden state for just the **last time step**. So the last time step for `out` should be identical to `hidden`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.392830Z",
     "start_time": "2018-11-12T07:48:59.386437Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9pPPfResPFnK",
    "nbpresent": {
     "id": "b4966fcb-563c-4483-9320-f536918865e7"
    },
    "outputId": "605acd04-8f7f-446f-d215-0c9698ea7a23",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "out[:,-1,:] # the last element in the *sequence* of outputs of the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.399719Z",
     "start_time": "2018-11-12T07:48:59.394842Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "afEtGcRUPFnO",
    "nbpresent": {
     "id": "6c282095-0983-47e3-bd3f-223966f26665"
    },
    "outputId": "ea2ddc68-2fdb-4896-95c7-e28a81938aac",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aFGY2gf7v_zP",
    "nbpresent": {
     "id": "07d82b7d-c9aa-4f01-9529-daac6cc17db9"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Yep, they both have the same values! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2KH5U4KHPFnZ",
    "nbpresent": {
     "id": "532c74ed-8836-4b19-bc07-747d64ec5a82"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inference with RNN: iterating through multiple sequences\n",
    "\n",
    "Now lets try multiple sequencse so we have more than 1 batch. \n",
    "\n",
    "Here we will consider 3 sequences each with the same length: \"hello\", \"eolll\", and \"lleel\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.410183Z",
     "start_time": "2018-11-12T07:48:59.401894Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "b-Da-6LAPFnZ",
    "nbpresent": {
     "id": "15c2bd34-4a8b-4ef4-a194-85215de223ae"
    },
    "outputId": "2ee7a801-50c8-4428-bf26-805e25b5840e",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# One cell RNN input_dim (4) -> output_dim (2). sequence: 5, batch 3\n",
    "# 3 batches 'hello', 'eolll', 'lleel'\n",
    "# rank = (3, 5, 4)\n",
    "inputs = Variable(torch.Tensor([[h, e, l, l, o],\n",
    "                                [e, o, l, l, l],\n",
    "                                [l, l, e, e, l]]))\n",
    "\n",
    "inputs.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We see from `inputs.size()` that the `inputs` tensor has size 3x5x4. These three dimensions correspond to:\n",
    "- dim 1: the number of sequences, 3 in this case\n",
    "- dim 2: the length of each sequence (ie the number of elements/characters in each sequence).  We have 5 characters for each sequence\n",
    "- dim 3: number of features to represent each character. Since we are using a 1-hot encoding scheme and we only have 4 characters, the number of features is just 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kqwoJFH4xaPl",
    "nbpresent": {
     "id": "61a981b9-b2fd-4faf-b9af-377336b8b379"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "OK, now that we have our inputs tensor setup, we now need to initialize the hidden state as before. \n",
    "\n",
    "The big difference before is because we have **three** sequences instead of one like the previous examples, we need to create three hidden tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.417891Z",
     "start_time": "2018-11-12T07:48:59.412450Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vHxx72RLPFne",
    "nbpresent": {
     "id": "228785b5-0376-4b3c-adc2-fd2e8578a0b9"
    },
    "outputId": "30a8d078-22f3-4a25-9ebe-f13b3ee4f162",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# hidden : (num_layers * num_directions, batch, hidden_size) whether batch_first=True or False\n",
    "hidden = Variable(torch.randn(1, 3, 2))\n",
    "hidden.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hq8j1_1szasT",
    "nbpresent": {
     "id": "204e923f-16fd-4187-8655-f9537fb32cde"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "In other words, we have created 3 different hidden states each having dimension 2. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now that we have our hidden states and inputs setup, lets forward pass them to Elman RNN!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.427023Z",
     "start_time": "2018-11-12T07:48:59.420376Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "yTUtdYmuPFng",
    "nbpresent": {
     "id": "a09ae730-46de-41dd-b952-1d289192ccdd"
    },
    "outputId": "6904aa29-6882-4cf1-fd4f-de015dd282a1",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Propagate input through RNN\n",
    "# Input: (batch, seq_len, input_size) when batch_first=True\n",
    "# B x S x I\n",
    "out, hidden = elman_rnn(inputs, hidden)\n",
    "print(\"batch input size\", inputs.size(), \"\\nout size\", out.size(), \"\\nhidden size\", hidden.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Because we have 3 sequences, the RNN will have 3 outputs. The first dimension of the `out` tensor 3. \n",
    "\n",
    "\n",
    "- Each sequence has length 5 characters, so the `out` tensor will have a hidden state for each of these characters. The middle dimension of `out` has 5 elements.\n",
    "\n",
    "\n",
    "- **Finally!** We have designed our RNN to have hidden states that are 2D. This is why we see that the third dimension of the `out` tensor is 2. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "OK, what about the `hidden` tensor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.436390Z",
     "start_time": "2018-11-12T07:48:59.429522Z"
    }
   },
   "outputs": [],
   "source": [
    "# Propagate input through RNN\n",
    "# Input: (batch, seq_len, input_size) when batch_first=True\n",
    "# B x S x I\n",
    "out, hidden = elman_rnn(inputs, hidden)\n",
    "print(\"batch input size\", inputs.size(), \"\\nout size\", out.size(), \"\\nhidden size\", hidden.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Remember the `hidden` tensor the RNN returns is just the *last* output of the hidden state from the last input character. Because we have 3 sequences, we 3 hidden states. And because we have 2 features in our hidden state, these 3 hidden states are 2D. \n",
    "\n",
    "\n",
    "- And as before, we expect that the *last* element in the `out` tensor should be equal to the `hidden` tensor for every sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise:  verify the *last* element in the `out` tensor should is equal to the `hidden` tensor for every sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.443500Z",
     "start_time": "2018-11-12T07:48:59.438303Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "AFgSJTtPPFnk",
    "nbpresent": {
     "id": "4cec4e20-2cb5-4edf-b536-405be09bcf36"
    },
    "outputId": "2a7dd45d-fb9e-4c9a-ffac-a676a71854d6",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ccUr7zFPFn0",
    "nbpresent": {
     "id": "b709e746-af87-4d77-9685-fff737d4f9ab"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Everything checks out!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "we can also not have the first dim be the batch size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.462112Z",
     "start_time": "2018-11-12T07:48:59.452410Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "x_M9Fw5KPFn0",
    "nbpresent": {
     "id": "cbd1ee20-13da-46a0-8612-c66287499079"
    },
    "outputId": "e4166997-9724-420c-bca5-8c861b85397a",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# One cell RNN input_dim (4) -> output_dim (2)\n",
    "elman_rnn = nn.RNN(input_size=4, hidden_size=2)\n",
    "\n",
    "# The given dimensions dim0 and dim1 are swapped.\n",
    "inputs = inputs.transpose(dim0=0, dim1=1)\n",
    "# Propagate input through RNN\n",
    "# Input: (seq_len, batch_size, input_size) when batch_first=False (default)\n",
    "# S x B x I\n",
    "out, hidden = elman_rnn(inputs, hidden)\n",
    "print(\"batch input size\", inputs.size(), \"out size\", out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H-kfoinTPFn2",
    "nbpresent": {
     "id": "640c9b45-8d79-4b59-b5dd-8115e856feb7"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Learning 1-batch sequence with RNN one element at a time\n",
    "\n",
    "Lets now apply RNN to *learn* a sequence. We will only consider one input sequence and one output sequence:\n",
    "\n",
    "- Input sequence: hihell\n",
    "- Output sequence: ihello\n",
    "\n",
    "We will design the 1-hot-encoding by first assigning an index to each character:\n",
    "- \"h\" -> 0\n",
    "- \"i\" -> 1\n",
    "- \"e\" -> 2\n",
    "- \"l\" -> 3\n",
    "- \"o\" -> 4\n",
    "\n",
    "So in other words we are living in a world that has only these 5 characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.468774Z",
     "start_time": "2018-11-12T07:48:59.464045Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "AftvYZLLPFn4",
    "nbpresent": {
     "id": "9cfd8355-7d22-4bb0-beb2-4c202fc93ee5"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(777)  # reproducibility\n",
    "#            0    1    2    3    4\n",
    "idx2char = ['h', 'i', 'e', 'l', 'o']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MYYcvo8UPFn7",
    "nbpresent": {
     "id": "f192656f-b2c0-4504-97ee-c22b6f2ded13"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We now define our sequence input sequence `x_data` \"hihell\"  and our output sequence `y_data` \"ihello\"\n",
    "\n",
    "We also convert our characters to one-hot-encoded vectors using a simple lookup table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.485899Z",
     "start_time": "2018-11-12T07:48:59.470989Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "jvIAxxesPFn8",
    "nbpresent": {
     "id": "7f7db4b2-45e1-4af4-bc61-6e0c72da3b6f"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Teach hihell -> ihello\n",
    "x_data = [0, 1, 0, 2, 3, 3]   # hihell\n",
    "y_data = [1, 0, 2, 3, 3, 4]   # ihello\n",
    "\n",
    "one_hot_lookup = [[1, 0, 0, 0, 0],  # 0\n",
    "                  [0, 1, 0, 0, 0],  # 1\n",
    "                  [0, 0, 1, 0, 0],  # 2\n",
    "                  [0, 0, 0, 1, 0],  # 3\n",
    "                  [0, 0, 0, 0, 1]]  # 4\n",
    "\n",
    "\n",
    "x_one_hot = [one_hot_lookup[x] for x in x_data]\n",
    "\n",
    "# As we have one batch of samples, we will change them to variables only once\n",
    "inputs = Variable(torch.Tensor(x_one_hot))\n",
    "labels = Variable(torch.LongTensor(y_data))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.492480Z",
     "start_time": "2018-11-12T07:48:59.487992Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "inputs.size(), labels.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eVZFnLMDMcky",
    "nbpresent": {
     "id": "64556b67-205b-4228-8720-2c25576d3aec"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The `inputs` tensor is size 6x5 because there are 6 characters and each character has 5 features. The outut `labels` tensor is just the character \"classes\" (ie, which character encodings) we want to predict.\n",
    "\n",
    "- The RNN we are going to use for predicting the next character is going to use the hidden state to directly in its prediction. \n",
    "\n",
    "- Normally this would be passed to another layer (like a fully connected layer or even another RNN) but in this example we are just going to  use it directly. \n",
    "- The advantage of using the hidden state directly and not introducing additional layers is we limit the number of parameters we have to learn. \n",
    "- The disadvantage of not using an additional layer is that we expect the hidden state to encode *both* the past histories *and* predict the next character. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.498919Z",
     "start_time": "2018-11-12T07:48:59.494764Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "p2Fh9retPFoB",
    "nbpresent": {
     "id": "bc3051c0-6a4f-410c-b95b-3c4fef118919"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 5      # the number of possible classes we have (the labels tensors is between 0 and 4)\n",
    "input_size = 5       # one-hot encoded vector dimensions\n",
    "hidden_size = 5      # we use 5 dimensional hidden state vectors to directly predict the character\n",
    "batch_size = 1       # we have one sentence and so one batch size\n",
    "sequence_length = 1  # we have only one sequence and we will process the characters one by one\n",
    "num_layers = 1       # we will have a simple one hidden layer RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mnv74fZOOPmT",
    "nbpresent": {
     "id": "43e09284-82cc-479e-89b7-618ee5b6213a"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we define our RNN class with the specific architecture that we want (as we usually do with PyTorch neural network models for training)\n",
    "\n",
    "We create our RNN model by inheriting from the `nn.Module`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is optional but very convenient.\n",
    "    \n",
    "To create our own RNN model with and satisfy the `nn.Module` API, we need to define the following two methods:\n",
    "\n",
    "- `__init__`\n",
    "- `forward`\n",
    "\n",
    "Can define any other supporting methods we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.530228Z",
     "start_time": "2018-11-12T07:48:59.500926Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "99rk_BLLPFoF",
    "nbpresent": {
     "id": "6905c272-4c4a-40dd-93ea-0a93c27b9b46"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size=self.input_size,\n",
    "                          hidden_size=self.hidden_size, \n",
    "                          batch_first=True)\n",
    "\n",
    "    def forward(self, hidden, x):\n",
    "        # Reshape input to make sure the first dim is batch dimension\n",
    "        x = x.view(batch_size, sequence_length, input_size)\n",
    "\n",
    "        # Propagate input through RNN\n",
    "        #   Input:  (batch, seq_len, input_size)\n",
    "        #            since we only have 1 batch and are iterating a single \n",
    "        #            character at a time we execpt the input tensor to have \n",
    "        #            shape: 1 x 1 x 5\n",
    "        #   hidden: (num_layers * num_directions, batch, hidden_size)\n",
    "        #            we only have 1 hidden layer and the RNN is uniderectional\n",
    "        #            so the hidden tensor size should be 1 x 1 x 5              \n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        return hidden, out.view(-1, num_classes)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Initialize hidden and cell states\n",
    "        # (num_layers * num_directions, batch, hidden_size)\n",
    "        #  we only have 1 hidden layer and the RNN is uniderectional\n",
    "        #  so the hidden tensor size should be 1 x 1 x 5   \n",
    "        return Variable(torch.zeros(num_layers, batch_size, hidden_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TOuTLcG-Osi-",
    "nbpresent": {
     "id": "cce15e4b-2fea-4535-ae92-b099e0041866"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we instantiate the model, define our loss criteron, and define the optimizer we want to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.541082Z",
     "start_time": "2018-11-12T07:48:59.534793Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "7H870MYhPFoH",
    "nbpresent": {
     "id": "a840188c-f5d0-45a6-8bfc-fd0fff8a4439"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate RNN model\n",
    "model = Model(input_size=5, hidden_size = 5)\n",
    "\n",
    "# Set loss and optimizer function\n",
    "# CrossEntropyLoss = LogSoftmax + NLLLoss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "# reducelron platue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TeJymCWsPCte",
    "nbpresent": {
     "id": "905bebc2-c872-4a44-8258-5f77757cc959"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Time to train the network!!!! \n",
    "\n",
    "We will loop through each epoch (100 of them), forward pass each individual character, then compute and accumulate the loss. Once the sequence is over, we compute the total loss and propagate the errors to update the network.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.820978Z",
     "start_time": "2018-11-12T07:48:59.544691Z"
    },
    "code_folding": [],
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "rA3E9fbBPFoJ",
    "nbpresent": {
     "id": "7a296331-7373-4ddf-9373-36b41c1b1d95"
    },
    "outputId": "6b2a41db-52bd-4138-dac6-5692caca93cc",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    hidden = model.init_hidden()\n",
    "    \n",
    "    # iterate through each character and predict what\n",
    "    # the next character should be.\n",
    "    pred_string = \"\"\n",
    "    for input, label in zip(inputs, labels):\n",
    "        hidden, output = model(hidden, input)\n",
    "        val, idx = output.max(1) # We are using the hidden state directly to make our \n",
    "                                 # prediction (and have reshaped appropriately in our \n",
    "                                 # Model class definition). We could also just as well \n",
    "                                 # use hidden state that we are returning as long as \n",
    "                                 # we reshape it right: \n",
    "                                 # hidden.view(-1, num_classes).max(1) \n",
    "        \n",
    "        pred_string += idx2char[idx.data[0]]\n",
    "        # accumulate the loss\n",
    "        loss += criterion(output, label.view(1))\n",
    "    \n",
    "    # ok we completed the sequence, lets backward prop and update the network\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # print every 20 epochs what the results look like\n",
    "    if (epoch%20 == 0) or (epoch == 99):\n",
    "        sys.stdout.write(\"predicted string: \")\n",
    "        sys.stdout.write(pred_string)\n",
    "        print(\", epoch: %d, loss: %1.3f\" % (epoch + 1, loss.item()))    \n",
    "    \n",
    "print(\"Learning finished!\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8gYILUvISsA6",
    "nbpresent": {
     "id": "71d430f4-d524-4819-840e-8bafa9f70430"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Looks like we learned (memorized, really) the target sequence!!!\n",
    "\n",
    "We can generalize this approach to multiple sequences: just have one more loop to iterate through each sequence. \n",
    "\n",
    "All of our sequences could also have different lengths and it would not matter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But often we are faced with sequences that always have the same length. \n",
    "\n",
    "In such cases we can update our RNN model to process not just a single character at a time, but the entire sequence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5cBl0Me3PFoO",
    "nbpresent": {
     "id": "c085e0b9-cb83-4a5b-b213-f65b92529fcb"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning 1-batch sequence with RNN (entire sequence)\n",
    "\n",
    "Now we are going to learn the sequence not character-by-character but the entire sequence at once. \n",
    "\n",
    "Another way of thinking about this is that we are learning batches of sequences. But since we only have 1 sequence, our batch size will be 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.826899Z",
     "start_time": "2018-11-12T07:48:59.823736Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "go2igLFrPFoQ",
    "nbpresent": {
     "id": "a3622e51-3be0-4e66-8fd5-56fce16d5378"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sequence_length = 6  # Since the number of character in our sequence |ihello| == 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TDvzUv2NUC3Q",
    "nbpresent": {
     "id": "0392549e-cd54-4203-bb7d-d155c023dc81"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We will similarly define the parameters of our model as variables below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.834651Z",
     "start_time": "2018-11-12T07:48:59.829576Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "U-gDSCPVnZfn",
    "nbpresent": {
     "id": "aecc3ed4-a933-45ab-b001-b2508c3c523f"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 5      # the number of possible classes we have (the labels tensors is between 0 and 4)\n",
    "input_size = 5       # one-hot encoded vector dimensions\n",
    "hidden_size = 5      # we use 5 dimensional hidden state vectors to directly predict the character\n",
    "batch_size = 1       # we have one sentence and so one batch size\n",
    "sequence_length = 1  # we have only one sequence and we will process the characters one by one\n",
    "num_layers = 1       # we will have a simple one hidden layer RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d9AsRC5VUIP4",
    "nbpresent": {
     "id": "1ee54806-5e84-417d-9aa2-128a458c7578"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we define our RNN class with the specific architecture that we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.866922Z",
     "start_time": "2018-11-12T07:48:59.838263Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "f-IIeOBIPFoV",
    "nbpresent": {
     "id": "1bee7228-bc18-4e10-8d2b-2d5e79a545da"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.rnn = nn.RNN(input_size=5, hidden_size=5, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states\n",
    "        # (num_layers * num_directions, batch, hidden_size) for batch_first=True\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
    "\n",
    "\n",
    "        # Propagate input through RNN\n",
    "        # Input: (batch, seq_len, input_size)\n",
    "        # h_0: (num_layers * num_directions, batch, hidden_size)\n",
    "\n",
    "        out, _ = self.rnn(x, h_0)\n",
    "        #return out\n",
    "        return out.view(-1, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.875221Z",
     "start_time": "2018-11-12T07:48:59.869106Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Tf7QfD4qp-EV",
    "nbpresent": {
     "id": "19c13bb5-d9ab-45db-aea9-d59aef7ed84b"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# As we have one batch of samples, we will change them to variables only once\n",
    "inputs = Variable(torch.Tensor(x_one_hot))\n",
    "labels = Variable(torch.LongTensor(y_data))\n",
    "\n",
    "inputs.size(), labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.882698Z",
     "start_time": "2018-11-12T07:48:59.877157Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "dls8lStsPFoY",
    "nbpresent": {
     "id": "5f40637c-5f3d-49e0-8cd8-412217a97958"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate RNN model\n",
    "rnn = RNN(num_classes, input_size, hidden_size, num_layers)\n",
    "\n",
    "# Set loss and optimizer function\n",
    "# CrossEntropyLoss = LogSoftmax + NLLLoss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:59.893553Z",
     "start_time": "2018-11-12T07:48:59.885777Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ia8GmMSQpfe8",
    "nbpresent": {
     "id": "d5e13557-a509-42e9-9662-ad036e1692ad"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "outputs = rnn(inputs.view(1,6,-1))\n",
    "outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:49:00.053876Z",
     "start_time": "2018-11-12T07:48:59.896461Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "G_Kab9RePFoZ",
    "nbpresent": {
     "id": "2345dd05-373c-48db-991c-290ff47a44f7"
    },
    "outputId": "f4e107d9-70af-4b27-dba4-1a8c75289df0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "for epoch in range(100):\n",
    "    outputs = rnn(inputs.view(1,6,-1))\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    _, idx = outputs.max(1)\n",
    "    idx = idx.data.numpy()\n",
    "    result_str = [idx2char[c] for c in idx.squeeze()]\n",
    "    if (epoch%20 == 0) or (epoch == 99):\n",
    "        print(\"epoch: %d, loss: %1.3f\" % (epoch + 1, loss.item()))\n",
    "        print(\"Predicted string: \", ''.join(result_str))\n",
    "    \n",
    "print(\"Learning finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "32JwvNzkPFoc",
    "nbpresent": {
     "id": "e8a53d45-8460-4206-a42a-d482b595f5ff"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Take home exercise: RNN with Embedding and Output layers\n",
    "\n",
    "- Instead of keeping the representation of characters fixed with one-hot encoding, we can also *learn* dense representations (kernels, templates, etc) of them\n",
    "\n",
    "- The Embedding layer is a special type of layer designed especially for sparse high dimensional 1-hot coded vectors\n",
    "\n",
    "- Use the embedding layer to pre-process the input before passing to the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:49:00.061249Z",
     "start_time": "2018-11-12T07:49:00.056004Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "-XiFI-LlPFoe",
    "nbpresent": {
     "id": "f1d4358a-56e5-4ee2-b17e-b33897e7d888"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x_data = [[0, 1, 0, 2, 3, 3]] \n",
    "# As we have one batch of samples, we will change them to variables only once\n",
    "inputs = Variable(torch.LongTensor(x_data))\n",
    "labels = Variable(torch.LongTensor(y_data))\n",
    "\n",
    "embedding_size = 10  # embedding size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:49:00.091108Z",
     "start_time": "2018-11-12T07:49:00.063277Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "mZSTBc9_PFoi",
    "nbpresent": {
     "id": "3c379071-2807-436c-8164-0e6676a05819"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, hidden_size):    \n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.RNN(input_size=embedding_size,\n",
    "                          hidden_size=self.hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states\n",
    "        # (num_layers * num_directions, batch, hidden_size)\n",
    "        #h_0 = Variable(torch.zeros(1, embedding_size, self.hidden_size))\n",
    "        h_0 = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "\n",
    "        emb = self.embedding(x)\n",
    "        emb = emb.view(batch_size, embedding_size, -1)\n",
    "        # Propagate embedding through RNN\n",
    "        # Input: (batch, seq_len, embedding_size)\n",
    "        # h_0: (num_layers * num_directions, batch, hidden_size)\n",
    "        out, _ = self.rnn(emb.view(1,6,-1), h_0)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:49:00.102315Z",
     "start_time": "2018-11-12T07:49:00.094290Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "bTcqAwMSPFok",
    "nbpresent": {
     "id": "9645650c-f514-4975-bb4e-bfad4b43a9bc"
    },
    "outputId": "7663599f-9817-4a3e-b40e-9de8da5efdc0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate RNN model\n",
    "model = Model(hidden_size)\n",
    "print(model)\n",
    "\n",
    "# Set loss and optimizer function\n",
    "# CrossEntropyLoss = LogSoftmax + NLLLoss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:49:00.276411Z",
     "start_time": "2018-11-12T07:49:00.104599Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "EEc-GWKfPFoo",
    "nbpresent": {
     "id": "8c640e8e-cd3c-4c03-8214-21a3845d8abe"
    },
    "outputId": "925db20e-bab9-49bb-fd21-e49f4f0341b2",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "for epoch in range(100):\n",
    "    outputs = model(inputs.view(1,-1)).view(-1,num_classes)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    _, idx = outputs.max(1)\n",
    "    idx = idx.data.numpy()\n",
    "    result_str = [idx2char[c] for c in idx.squeeze()]\n",
    "    if (epoch%20 == 0) or (epoch == 99):\n",
    "        print(\"epoch: %d, loss: %1.3f\" % (epoch + 1, loss.data[0]))\n",
    "        print(\"Predicted string: \", ''.join(result_str))\n",
    "\n",
    "print(\"Learning finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "name": "PyTorch-RNN-next-char-pred.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
