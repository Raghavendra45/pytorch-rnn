{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "etMAh1TAxxec",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Remembering Problem\n",
    "\n",
    "The \"remembering problem\" is a variant of the \"adding problem\" proposed by Schmidhuber and colleagues as an example of a sequential task that LSTM's are particularly well suited for: http://people.idsia.ch/~juergen/nipslstm/node4.html\n",
    "\n",
    "### Mehrdad Yazdani\n",
    "### November 12, 2018\n",
    "\n",
    "Colab notebook online to play!!\n",
    "\n",
    "https://colab.research.google.com/drive/13dNJ66vjiswqofcfcnecDeyY_DCeYYlq#scrollTo=qJMFpFxOiKja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![frequent words](https://blogs.sas.com/content/sastraining/files/2015/11/word_frequency.png)\n",
    "\n",
    "Data source: http://norvig.com/google-books-common-words.txt\n",
    "\n",
    "\n",
    "All methods will be compared using MSE on a held out test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:59:50.636728Z",
     "start_time": "2018-11-12T07:59:48.241327Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "dqSmie_KEun4",
    "outputId": "0149a656-8ce1-4c9f-ec1f-284f75dcd2ba",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /anaconda3/lib/python3.6/site-packages (0.4.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:59:51.443563Z",
     "start_time": "2018-11-12T07:59:50.640152Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "squ9-CcuEwHF",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "import collections\n",
    "\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns;\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:59:51.570658Z",
     "start_time": "2018-11-12T07:59:51.446078Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "v49i2wJgJoZm",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:59:51.579328Z",
     "start_time": "2018-11-12T07:59:51.573466Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "k4-F5eWl6zI1",
    "outputId": "2dedfe02-daf9-4b5f-e99e-9de78d645ff7",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using CPU!\n"
     ]
    }
   ],
   "source": [
    "# use CUDA or not\n",
    "use_cuda = False\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "  print(\"using cuda!\")\n",
    "  device = torch.device(\"cuda\")\n",
    "else:\n",
    "  print(\"using CPU!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HEuvUaYKynm5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data loading functions\n",
    "\n",
    "We will define some helper functions to generate our datasets. `generate_sequence` will genrate a single sequence whereas `get_set` returns multiple sequences (so a *dataset* of sequences).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:59:51.599970Z",
     "start_time": "2018-11-12T07:59:51.581689Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "cVkyE3gT5wWI",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def generate_char_seq(seq_len = 10):\n",
    "  return ''.join(random.choice(string.ascii_lowercase) for _ \n",
    "                 in range(seq_len))\n",
    "\n",
    "def get_set(num_examples = 100, seq_len = 10):\n",
    "  one_hot_encoded = {}\n",
    "  for i, char in enumerate(list(string.ascii_lowercase)):\n",
    "    one_hot_encoded[char] = i\n",
    "\n",
    "  X_seqs = []\n",
    "  num_repeats = []\n",
    "\n",
    "  for _ in range(num_examples):\n",
    "    seq_example = generate_char_seq(seq_len)\n",
    "    X_seqs.append([one_hot_encoded[char] for char in list(seq_example)])\n",
    "    num_repeats.append(collections.Counter(seq_example).most_common(1)[0][1])\n",
    "    \n",
    "  return np.array(X_seqs), np.array(num_repeats)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b1x7uKBP0ZNk",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Lets see `get_set` in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:59:51.611506Z",
     "start_time": "2018-11-12T07:59:51.602237Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gsJVFU_75wTp",
    "outputId": "e62ce919-4e75-421e-d4ef-04e785f7eb26",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21,  6,  9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = get_set(num_examples=100, seq_len = 3)\n",
    "X_train[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ES3lsroR0jpu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So for the input we have a 2D array that has shape \"num examples\" x \"sequence length\" \n",
    "\n",
    "Note that the datasets that `get_set` returns are Numpy arrays, but PyTorch recquires PyTorch tensors. We could of course convert these Numpy arrays to PyTorch arrays, and then do some booking with indices to keep track of going through different batches when doing batch updates on the network.\n",
    "\n",
    "But that is tedious and PyTorch offers the Dataset class that we can inherit from to keep all this bookkeeping for us. Below we define the `SequenceDataset` generator class that will be used for all our data handilng for PyTorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:59:51.637659Z",
     "start_time": "2018-11-12T07:59:51.614380Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "KGH1kJTGGvFN",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "  \n",
    "  def __init__(self, num_examples, seq_len):\n",
    "    self.num_examples = num_examples\n",
    "    self.seq_len = seq_len\n",
    "    \n",
    "    X, y = get_set(num_examples=self.num_examples, seq_len = self.seq_len)\n",
    "    self.X = torch.LongTensor(X)\n",
    "    self.y = torch.from_numpy(y).float()\n",
    "    if use_cuda and torch.cuda.is_available():\n",
    "      self.X = self.X.to(device)\n",
    "      self.y = self.y.to(device)\n",
    "    \n",
    "    \n",
    "    \n",
    "  def __getitem__(self, index):\n",
    "    return self.X[index], self.y[index]\n",
    "  \n",
    "  def __len__(self):\n",
    "    return self.num_examples\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fZmrufss26CF",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Lets create a training and test set with 100 examples for each and sequence lengths of 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:59:51.653032Z",
     "start_time": "2018-11-12T07:59:51.641830Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "NPsIkWsTJxro",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "train_set = SequenceDataset(num_examples=100, seq_len = 10)\n",
    "test_set = SequenceDataset(num_examples=100, seq_len = 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CxjZMwEy3IaT",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can use PyTorch's `DataLoader` to specify the the batches of data to load for training. Note that each of the 100 example sequences are independent, so we also shuffle the order of the different sequences. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:59:51.662596Z",
     "start_time": "2018-11-12T07:59:51.657345Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "7-Rj0yQu3prw",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(dataset = train_set,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle = True)\n",
    "\n",
    "test_loader = DataLoader(dataset = test_set,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f-khUeqXF2_g",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RNN\n",
    "\n",
    "We will start solving the Remembering Problem with a simple RNN (the *Elman Network*). The network will update its internal hidden state for every element in the sequence until we reach the end. When we reach the end, we pass the final hidden state through a fully connected linear layer to predict the target. This type of architecture is sometimes called *many-to-one* since we are taking \"many\" elements (a sequence) to a single element (the target).\n",
    "\n",
    "<center>\n",
    "![Many to one](https://i.stack.imgur.com/QCnpU.jpg)\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:59:51.694135Z",
     "start_time": "2018-11-12T07:59:51.665933Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "GhkM836zGW82",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class RNNRemember(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, embedding_size, input_size):    \n",
    "        super(RNNRemember, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.embedding = nn.Embedding(input_size, self.embedding_size)\n",
    "        self.rnn = nn.RNN(input_size=embedding_size,\n",
    "                          hidden_size=self.hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states\n",
    "        # (num_layers * num_directions, batch, hidden_size)\n",
    "        #h_0 = Variable(torch.zeros(1, embedding_size, self.hidden_size))\n",
    "        h_0 = Variable(torch.zeros(1, x.size(0), self.hidden_size))\n",
    "\n",
    "        emb = self.embedding(x)\n",
    "        # Propagate embedding through RNN\n",
    "        # Input: (batch, seq_len, embedding_size)\n",
    "        # h_0: (num_layers * num_directions, batch, hidden_size)\n",
    "        _, h_f = self.rnn(emb, h_0)\n",
    "        return self.fc(h_f).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:59:51.703109Z",
     "start_time": "2018-11-12T07:59:51.696189Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "J2ukZFPkJkNz",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "rnn_remember = RNNRemember(hidden_size = 50, embedding_size = 5, \n",
    "                           input_size = len(string.ascii_lowercase))\n",
    "\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    rnn_adder = rnn_adder.cuda(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:59:51.709090Z",
     "start_time": "2018-11-12T07:59:51.705530Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "73HZrMRDKPz2",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Set loss and optimizer function\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(rnn_remember.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T08:00:02.273209Z",
     "start_time": "2018-11-12T07:59:51.711001Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "uONrEQwF93-r",
    "outputId": "2681ac89-685a-405f-cf38-8bf97040a6a0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 0.0008117657853290439\n",
      "loss is 0.0007380075985565782\n",
      "loss is 1.7095851944759488e-05\n",
      "loss is 0.0009870203211903572\n",
      "loss is 3.625319777711411e-06\n",
      "loss is 1.6261276414297754e-07\n",
      "loss is 1.9569256437534932e-07\n",
      "loss is 0.009279856458306313\n",
      "loss is 0.0003926208592019975\n",
      "loss is 1.5202015674731229e-05\n",
      "CPU times: user 10.5 s, sys: 74 ms, total: 10.5 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "  for i, (sequences, targets) in enumerate(train_loader):\n",
    "    if use_cuda and torch.cuda.is_available():\n",
    "      sequences = sequences.to(device)\n",
    "      targets = targets.to(device)\n",
    "\n",
    "    \n",
    "    # forward pass\n",
    "    outputs = rnn_remember(sequences)\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    # update weights\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "  if (epoch+1)%100 == 0:\n",
    "    print(\"loss is\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T08:00:02.280989Z",
     "start_time": "2018-11-12T08:00:02.275230Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YOBl0zXCIUa0",
    "outputId": "02ddef5d-9eca-4798-a8ee-7cd7f24506de",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4686804711818695\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  outputs = rnn_remember(test_set.X)\n",
    "  test_mse = torch.mean((outputs - test_set.y)**2)\n",
    "print(test_mse.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-BJIjhpEHwSW",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LSTM\n",
    "\n",
    "RNN's suffer from the vanishing gradient problem since creating the final hidden state is a result of updating the state through multiplications everytime a new element arrives in the sequence. LSTM's bypass this challenge by updating state additively. As a result, updaing gradients is much easier and longer memories can persist. Below is an `LSTMRemember` that is nearly identical to the `RNNRemember`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T08:00:02.317778Z",
     "start_time": "2018-11-12T08:00:02.282756Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "mhr2amTvEshB",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class LSTMRemember(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, input_size, embedding_size):    \n",
    "        super(LSTMRemember, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.embedding = nn.Embedding(input_size, self.embedding_size)\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_size,\n",
    "                          hidden_size=self.hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states\n",
    "        # (num_layers * num_directions, batch, hidden_size)\n",
    "        h_0 = Variable(torch.zeros(1, x.size(0), self.hidden_size))\n",
    "        c_0 = Variable(torch.zeros(1, x.size(0), self.hidden_size))\n",
    "        if use_cuda and torch.cuda.is_available():\n",
    "          h_0 = h_0.to(device)\n",
    "          c_0 = c_0.to(device)\n",
    "          \n",
    "                  \n",
    "        emb = self.embedding(x)\n",
    "        # Propagate input through LSTM\n",
    "        # Input: (batch, seq_len, embedding_size)\n",
    "        # h_0: (num_layers * num_directions, batch, hidden_size)\n",
    "        _, (h_f, c_f) = self.lstm(emb, (h_0, c_0))\n",
    "        return self.fc(h_f).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T08:00:02.324619Z",
     "start_time": "2018-11-12T08:00:02.320258Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Zp2NuPyIKFBN",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "lstm_remember = LSTMRemember(hidden_size = 50, embedding_size = 5, \n",
    "                           input_size = len(string.ascii_lowercase))\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    lstm_remember = lstm_remember.cuda(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T08:00:02.330012Z",
     "start_time": "2018-11-12T08:00:02.326700Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Ay85qAOeKJTT",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Set loss and optimizer function\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(lstm_remember.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T08:03:28.552107Z",
     "start_time": "2018-11-12T08:00:02.332652Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1751
    },
    "colab_type": "code",
    "id": "sEr3G2M0KLXA",
    "outputId": "54f44f60-9d4c-440a-b036-a47e80289b06",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 0.05242282152175903\n",
      "loss is 0.004597179125994444\n",
      "loss is 8.74446050147526e-06\n",
      "loss is 5.7140850913128816e-06\n",
      "loss is 0.0014133139047771692\n",
      "loss is 2.0836645489907824e-05\n",
      "loss is 0.003276211442425847\n",
      "loss is 1.7728017382978578e-06\n",
      "loss is 2.5956552462957916e-09\n",
      "loss is 1.6632615285061547e-08\n",
      "loss is 0.00013779960863757879\n",
      "loss is 8.683727514835482e-09\n",
      "loss is 1.732466969883717e-08\n",
      "loss is 0.0011564528103917837\n",
      "loss is 2.135296381311491e-05\n",
      "loss is 7.596679643029347e-05\n",
      "loss is 1.2502432582550682e-05\n",
      "loss is 1.0631826626195107e-05\n",
      "loss is 0.0006299148662947118\n",
      "loss is 0.000237882457440719\n",
      "loss is 1.7092472148760862e-07\n",
      "loss is 1.939519734150963e-06\n",
      "loss is 0.0010226396843791008\n",
      "loss is 0.0004548224969767034\n",
      "loss is 5.448233423521742e-05\n",
      "loss is 7.408260671581957e-10\n",
      "loss is 3.3146818623208674e-12\n",
      "loss is 1.2825296380469808e-12\n",
      "loss is 5.30038323631743e-06\n",
      "loss is 0.00039897108217701316\n",
      "loss is 2.3759685063851066e-05\n",
      "loss is 8.414247076871106e-11\n",
      "loss is 1.7763568394002505e-14\n",
      "loss is 2.35548469618152e-10\n",
      "loss is 0.0002894533099606633\n",
      "loss is 7.933938661608408e-08\n",
      "loss is 1.2686641071013582e-08\n",
      "loss is 8.080913289632008e-07\n",
      "loss is 0.002617861609905958\n",
      "loss is 2.2927792997506913e-10\n",
      "loss is 3.446132268436486e-13\n",
      "loss is 2.3220536604640074e-11\n",
      "loss is 1.042506755766226e-05\n",
      "loss is 3.9090245991246775e-05\n",
      "loss is 2.363711246289313e-05\n",
      "loss is 1.251947537639353e-06\n",
      "loss is 5.298003316056565e-07\n",
      "loss is 4.449313200893812e-05\n",
      "loss is 4.0480761526850984e-05\n",
      "loss is 3.019181349372957e-06\n",
      "loss is 2.6009833163698204e-05\n",
      "loss is 7.939473078977244e-08\n",
      "loss is 6.061751628294587e-05\n",
      "loss is 7.762895620544441e-06\n",
      "loss is 1.6118661960717873e-10\n",
      "loss is 1.671456516305625e-06\n",
      "loss is 0.0002748412371147424\n",
      "loss is 3.527939770719968e-05\n",
      "loss is 4.769046313413128e-08\n",
      "loss is 1.7348384062643163e-08\n",
      "loss is 0.0003889307554345578\n",
      "loss is 5.681611582986079e-06\n",
      "loss is 2.402071430651631e-09\n",
      "loss is 9.63856905400462e-09\n",
      "loss is 0.0005922375130467117\n",
      "loss is 1.7527269164929749e-06\n",
      "loss is 6.799083962505392e-08\n",
      "loss is 3.7962283272463537e-07\n",
      "loss is 2.217899009337998e-06\n",
      "loss is 8.981970722743426e-11\n",
      "loss is 9.030429737322265e-09\n",
      "loss is 0.0014405813999474049\n",
      "loss is 6.70499389343604e-09\n",
      "loss is 1.2936013149555947e-08\n",
      "loss is 0.0003084621566813439\n",
      "loss is 0.00015261158114299178\n",
      "loss is 1.3580768154497491e-06\n",
      "loss is 8.390970833715983e-07\n",
      "loss is 2.815550942614209e-05\n",
      "loss is 1.38605319079943e-05\n",
      "loss is 2.567807086961693e-07\n",
      "loss is 1.7145667641216278e-07\n",
      "loss is 0.0014253498520702124\n",
      "loss is 1.362095304102695e-06\n",
      "loss is 5.825418156746309e-07\n",
      "loss is 8.807816698208626e-10\n",
      "loss is 7.744846186596988e-08\n",
      "loss is 2.6328296371502802e-05\n",
      "loss is 6.424944132277233e-09\n",
      "loss is 1.7779673555651243e-07\n",
      "loss is 5.5676016927463934e-05\n",
      "loss is 2.3495385903515853e-06\n",
      "loss is 2.147835857613245e-06\n",
      "loss is 6.083654807298444e-05\n",
      "loss is 2.42352962231962e-06\n",
      "loss is 0.000783863477408886\n",
      "loss is 5.094361199553532e-08\n",
      "loss is 1.8323535755371267e-07\n",
      "loss is 4.0559651637295246e-08\n",
      "loss is 0.00010001821647165343\n",
      "CPU times: user 3min 27s, sys: 8.97 s, total: 3min 36s\n",
      "Wall time: 3min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "  for i, (sequences, targets) in enumerate(train_loader):\n",
    "    # forward pass\n",
    "    outputs = lstm_remember(sequences)\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "  if (epoch+1)%100 == 0:\n",
    "    print(\"loss is\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T08:03:28.563535Z",
     "start_time": "2018-11-12T08:03:28.554104Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VqCzc4weKPRL",
    "outputId": "5d425b04-4218-4132-fc35-d540102ed9f9",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44475048780441284\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  outputs = lstm_remember(test_set.X)\n",
    "  test_mse = torch.mean((outputs - test_set.y)**2)\n",
    "print(test_mse.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qJMFpFxOiKja",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ReLU RNN\n",
    "\n",
    "The idea of the ReLU RNN is to initialize the hidden state of the RNN with the identity matrix and the bias with 0 and use the ReLU activation function. Below we demonstrate how such an RNN can be implemented. The results are not as good as the LSTM but certainly better than the traditional Elman Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uy2C1wItLTl3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Slideshow",
  "colab": {
   "name": "The-Remembering-Problem-PyTorch.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
